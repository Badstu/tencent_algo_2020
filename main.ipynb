{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.imooc.com/article/43784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sayhi/workspaces/tencent_algo_2020\n"
     ]
    }
   ],
   "source": [
    "cd tencent_algo_2020/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "\n",
    "import time\n",
    "import data\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, accuracy_score\n",
    "from gensim.models import word2vec, keyedvectors\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchnet import meter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "# from mytorch.dataset import RecordDataset\n",
    "# from mytorch.lstm import ClickRNN\n",
    "\n",
    "from model import lgb_model\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncreative_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/creative_model.w2v\", binary=True)\\nad_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/ad_model.w2v\", binary=True)\\nproduct_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/product_model.w2v\", binary=True)\\nadvertiser_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/advertiser_model.w2v\", binary=True)\\nindustry_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/industry_model.w2v\", binary=True)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "creative_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/creative_model.w2v\", binary=True)\n",
    "ad_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/ad_model.w2v\", binary=True)\n",
    "product_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/product_model.w2v\", binary=True)\n",
    "advertiser_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/advertiser_model.w2v\", binary=True)\n",
    "industry_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/industry_model.w2v\", binary=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ad, train_click, train_user, test_ad, test_click = data.load_data()\n",
    "# train_record\n",
    "train_record = pd.merge(train_click, train_ad, on=\"creative_id\")\n",
    "# test_record\n",
    "test_record = pd.merge(test_click, test_ad, on=\"creative_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouped = train_record.groupby(\"user_id\")\n",
    "test_grouped = test_record.groupby(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>click_times</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category</th>\n",
       "      <th>advertiser_id</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>30920</td>\n",
       "      <td>567330</td>\n",
       "      <td>1</td>\n",
       "      <td>504423</td>\n",
       "      <td>30673.0</td>\n",
       "      <td>3</td>\n",
       "      <td>32638</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>320815</td>\n",
       "      <td>567330</td>\n",
       "      <td>1</td>\n",
       "      <td>504423</td>\n",
       "      <td>30673.0</td>\n",
       "      <td>3</td>\n",
       "      <td>32638</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>355089</td>\n",
       "      <td>567330</td>\n",
       "      <td>1</td>\n",
       "      <td>504423</td>\n",
       "      <td>30673.0</td>\n",
       "      <td>3</td>\n",
       "      <td>32638</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>363442</td>\n",
       "      <td>567330</td>\n",
       "      <td>1</td>\n",
       "      <td>504423</td>\n",
       "      <td>30673.0</td>\n",
       "      <td>3</td>\n",
       "      <td>32638</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>370513</td>\n",
       "      <td>567330</td>\n",
       "      <td>1</td>\n",
       "      <td>504423</td>\n",
       "      <td>30673.0</td>\n",
       "      <td>3</td>\n",
       "      <td>32638</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>31</td>\n",
       "      <td>606288</td>\n",
       "      <td>1370845</td>\n",
       "      <td>1</td>\n",
       "      <td>1197877</td>\n",
       "      <td>26858.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7170</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>41</td>\n",
       "      <td>608609</td>\n",
       "      <td>1370845</td>\n",
       "      <td>1</td>\n",
       "      <td>1197877</td>\n",
       "      <td>26858.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7170</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>29</td>\n",
       "      <td>608609</td>\n",
       "      <td>1370845</td>\n",
       "      <td>1</td>\n",
       "      <td>1197877</td>\n",
       "      <td>26858.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7170</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>34</td>\n",
       "      <td>608749</td>\n",
       "      <td>1370845</td>\n",
       "      <td>1</td>\n",
       "      <td>1197877</td>\n",
       "      <td>26858.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7170</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>33</td>\n",
       "      <td>60993</td>\n",
       "      <td>1370845</td>\n",
       "      <td>1</td>\n",
       "      <td>1197877</td>\n",
       "      <td>26858.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7170</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time  user_id  creative_id  click_times    ad_id  product_id  \\\n",
       "0        9    30920       567330            1   504423     30673.0   \n",
       "1       15   320815       567330            1   504423     30673.0   \n",
       "2       11   355089       567330            1   504423     30673.0   \n",
       "3        9   363442       567330            1   504423     30673.0   \n",
       "4       14   370513       567330            1   504423     30673.0   \n",
       "...    ...      ...          ...          ...      ...         ...   \n",
       "4995    31   606288      1370845            1  1197877     26858.0   \n",
       "4996    41   608609      1370845            1  1197877     26858.0   \n",
       "4997    29   608609      1370845            1  1197877     26858.0   \n",
       "4998    34   608749      1370845            1  1197877     26858.0   \n",
       "4999    33    60993      1370845            1  1197877     26858.0   \n",
       "\n",
       "      product_category  advertiser_id  industry  \n",
       "0                    3          32638     319.0  \n",
       "1                    3          32638     319.0  \n",
       "2                    3          32638     319.0  \n",
       "3                    3          32638     319.0  \n",
       "4                    3          32638     319.0  \n",
       "...                ...            ...       ...  \n",
       "4995                 3           7170      60.0  \n",
       "4996                 3           7170      60.0  \n",
       "4997                 3           7170      60.0  \n",
       "4998                 3           7170      60.0  \n",
       "4999                 3           7170      60.0  \n",
       "\n",
       "[5000 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "sample_record = train_record[:5000]\n",
    "sample_record\n",
    "\n",
    "sample_grouped = sample_record.groupby(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_grouped = sample_grouped.agg(list).reset_index()\n",
    "list_grouped = pd.merge(list_grouped, train_user, on=\"user_id\")\n",
    "# for user_id, record in sample_grouped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>click_times</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category</th>\n",
       "      <th>advertiser_id</th>\n",
       "      <th>industry</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>[49]</td>\n",
       "      <td>[2361327]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[2035918]</td>\n",
       "      <td>[1261.0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[6783]</td>\n",
       "      <td>[6.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>[67]</td>\n",
       "      <td>[3072255]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[2642300]</td>\n",
       "      <td>[1261.0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[6783]</td>\n",
       "      <td>[6.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117</td>\n",
       "      <td>[66]</td>\n",
       "      <td>[2361327]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[2035918]</td>\n",
       "      <td>[1261.0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[6783]</td>\n",
       "      <td>[6.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217</td>\n",
       "      <td>[50]</td>\n",
       "      <td>[2361327]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[2035918]</td>\n",
       "      <td>[1261.0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[6783]</td>\n",
       "      <td>[6.0]</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>528</td>\n",
       "      <td>[71, 73, 49]</td>\n",
       "      <td>[3072255, 3072255, 2361327]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[2642300, 2642300, 2035918]</td>\n",
       "      <td>[1261.0, 1261.0, 1261.0]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>[6783, 6783, 6783]</td>\n",
       "      <td>[6.0, 6.0, 6.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>899189</td>\n",
       "      <td>[89]</td>\n",
       "      <td>[2851451]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[2451406]</td>\n",
       "      <td>[29664.0]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[28212]</td>\n",
       "      <td>[242.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3873</th>\n",
       "      <td>899379</td>\n",
       "      <td>[72]</td>\n",
       "      <td>[3072255]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[2642300]</td>\n",
       "      <td>[1261.0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[6783]</td>\n",
       "      <td>[6.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>899662</td>\n",
       "      <td>[61]</td>\n",
       "      <td>[2361327]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[2035918]</td>\n",
       "      <td>[1261.0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[6783]</td>\n",
       "      <td>[6.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3875</th>\n",
       "      <td>899825</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[197866]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[177626]</td>\n",
       "      <td>[26858.0]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[2367]</td>\n",
       "      <td>[60.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>899850</td>\n",
       "      <td>[66]</td>\n",
       "      <td>[2361327]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[2035918]</td>\n",
       "      <td>[1261.0]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[6783]</td>\n",
       "      <td>[6.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3877 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id          time                  creative_id click_times  \\\n",
       "0           8          [49]                    [2361327]         [1]   \n",
       "1          90          [67]                    [3072255]         [1]   \n",
       "2         117          [66]                    [2361327]         [1]   \n",
       "3         217          [50]                    [2361327]         [1]   \n",
       "4         528  [71, 73, 49]  [3072255, 3072255, 2361327]   [1, 1, 1]   \n",
       "...       ...           ...                          ...         ...   \n",
       "3872   899189          [89]                    [2851451]         [1]   \n",
       "3873   899379          [72]                    [3072255]         [1]   \n",
       "3874   899662          [61]                    [2361327]         [1]   \n",
       "3875   899825           [6]                     [197866]         [1]   \n",
       "3876   899850          [66]                    [2361327]         [1]   \n",
       "\n",
       "                            ad_id                product_id product_category  \\\n",
       "0                       [2035918]                  [1261.0]              [2]   \n",
       "1                       [2642300]                  [1261.0]              [2]   \n",
       "2                       [2035918]                  [1261.0]              [2]   \n",
       "3                       [2035918]                  [1261.0]              [2]   \n",
       "4     [2642300, 2642300, 2035918]  [1261.0, 1261.0, 1261.0]        [2, 2, 2]   \n",
       "...                           ...                       ...              ...   \n",
       "3872                    [2451406]                 [29664.0]              [3]   \n",
       "3873                    [2642300]                  [1261.0]              [2]   \n",
       "3874                    [2035918]                  [1261.0]              [2]   \n",
       "3875                     [177626]                 [26858.0]              [3]   \n",
       "3876                    [2035918]                  [1261.0]              [2]   \n",
       "\n",
       "           advertiser_id         industry  age  gender  \n",
       "0                 [6783]            [6.0]    5       1  \n",
       "1                 [6783]            [6.0]    3       2  \n",
       "2                 [6783]            [6.0]    2       1  \n",
       "3                 [6783]            [6.0]    7       2  \n",
       "4     [6783, 6783, 6783]  [6.0, 6.0, 6.0]    2       1  \n",
       "...                  ...              ...  ...     ...  \n",
       "3872             [28212]          [242.0]    5       1  \n",
       "3873              [6783]            [6.0]    3       1  \n",
       "3874              [6783]            [6.0]    6       1  \n",
       "3875              [2367]           [60.0]    3       1  \n",
       "3876              [6783]            [6.0]    6       1  \n",
       "\n",
       "[3877 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3877"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_grouped\n",
    "len(list_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordDataset(Dataset):\n",
    "    def __init__(self, list_grouped):\n",
    "        self.creative_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/creative_model.w2v\", binary=True)\n",
    "        self.ad_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/ad_model.w2v\", binary=True)\n",
    "        self.product_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/product_model.w2v\", binary=True)\n",
    "        self.advertiser_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/advertiser_model.w2v\", binary=True)\n",
    "        self.industry_model = keyedvectors.KeyedVectors.load_word2vec_format(\"checkpoints/industry_model.w2v\", binary=True)\n",
    "        \n",
    "        self.list_grouped = list_grouped\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        #这里需要注意的是，第一步：read one data，是一个data\n",
    "        record = self.list_grouped.iloc[index, :]\n",
    "        user_id = record[\"user_id\"]\n",
    "        t = len(record[\"ad_id\"])\n",
    "        age = record[\"age\"]\n",
    "        gender = record[\"gender\"]\n",
    "        \n",
    "        # ad_embedding\n",
    "        ad_embedding = self.get_embedding_from_grouped(user_id, record, column_name=\"ad_id\")\n",
    "        #creative_embedding\n",
    "        creative_embedding = self.get_embedding_from_grouped(user_id, record, column_name=\"creative_id\")\n",
    "        #product_embedding\n",
    "        product_embedding = self.get_embedding_from_grouped(user_id, record, column_name=\"product_id\")\n",
    "        #advertiser_embedding\n",
    "        advertiser_embedding = self.get_embedding_from_grouped(user_id, record, column_name=\"advertiser_id\")\n",
    "        #industry_embedding\n",
    "        industry_embedding = self.get_embedding_from_grouped(user_id, record, column_name=\"industry\")\n",
    "        \n",
    "        embed_features = torch.cat([ad_embedding, creative_embedding, product_embedding, advertiser_embedding, industry_embedding], dim=1)\n",
    "            \n",
    "        return t, embed_features, age, gender\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.list_grouped)\n",
    "    \n",
    "    \n",
    "    def get_embedding_from_grouped(self, user_id, record, column_name):\n",
    "        if column_name == \"ad_id\":\n",
    "            model = self.ad_model\n",
    "        elif column_name == \"creative_id\":\n",
    "            model = self.creative_model\n",
    "        elif column_name == \"industry\":\n",
    "            model = self.industry_model\n",
    "        elif column_name == \"product_id\":\n",
    "            model = self.product_model\n",
    "        elif column_name == \"advertiser_id\":\n",
    "            model = self.advertiser_model\n",
    "\n",
    "        if column_name == \"industry\":\n",
    "            embedding = [np.zeros(100, ) if pd.isnull(x) else model[str(int(x))] for x in record[column_name]]\n",
    "        elif column_name == \"product_id\":\n",
    "            embedding = [np.zeros(200, ) if pd.isnull(x) else model[str(int(x))] for x in record[column_name]]\n",
    "        else:\n",
    "            embedding = [model[str(x)] for x in record[column_name]]\n",
    "        \n",
    "        embedding = torch.Tensor(embedding)\n",
    "        \n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = RecordDataset(list_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    data.sort(key = lambda x: x[0], reverse=True)\n",
    "    t = [x[0] for x in data]\n",
    "    embed_features = [x[1] for x in data]\n",
    "    age = [x[2] for x in data]\n",
    "    gender = [x[3] for x in data]\n",
    "\n",
    "    embed_features = rnn_utils.pad_sequence(embed_features, batch_first=True, padding_value=0)\n",
    "    # embed_features = rnn_utils.pack_padded_sequence(embed_features, lengths=t, batch_first=True)\n",
    "    return t, embed_features, age, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataloader = DataLoader(sample_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, embed_features, age, gender = iter(sample_dataloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClickRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, batch_size, bidirectional=True, drop_prob=0.5, train_on_gpu=False):\n",
    "        super(ClickRNN, self).__init__()\n",
    "         \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.batch_size = batch_size\n",
    "        self.train_on_gpu = train_on_gpu\n",
    "        \n",
    "        # self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True,\n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        if bidirectional:\n",
    "          self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        else:\n",
    "          self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "          \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    " \n",
    "    def forward(self, x, hidden=None):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        \n",
    "        # embeddings and lstm_out\n",
    "#         x = x.long()\n",
    "#         embeds = self.embedding(x)\n",
    "        \n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(self.train_on_gpu)\n",
    "        \n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # sigmoid function\n",
    "        sig_out = self.sigmoid(out)\n",
    "        out = sig_out[:, -1, :]\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, train_on_gpu):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        number = 1\n",
    "        if self.bidirectional:\n",
    "           number = 2\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers*number, self.batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                      weight.new(self.n_layers*number, self.batch_size, self.hidden_dim).zero_().cuda()\n",
    "                     )\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers*number, self.batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers*number, self.batch_size, self.hidden_dim).zero_()\n",
    "                     )\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_net = ClickRNN(input_dim=800, hidden_dim=200, output_dim=1, n_layers=1, batch_size=64)\n",
    "age_net = ClickRNN(input_dim=800, hidden_dim=200, output_dim=10, n_layers=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_out, length, hidden = gender_net(embed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_out, length, _ = age_net(embed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_list, valid_list, model_type=\"gender\"):\n",
    "    batch_size = 64\n",
    "    hidden_dim = 200\n",
    "    train_on_gpu=True\n",
    "    device = torch.device(\"cuda\") if train_on_gpu else torch.device(\"cpu\")\n",
    "    \n",
    "    model_path = None\n",
    "    lr = 1e-5\n",
    "    lr_decay = 0.95\n",
    "    weight_decay = 1e-5\n",
    "    \n",
    "    max_epoch = 50\n",
    "    \n",
    "    train_dataset = RecordDataset(train_list)\n",
    "    valid_dataset = RecordDataset(valid_list)\n",
    "#     test_dataset = RecordDataset(test_list)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                              num_workers=8, drop_last=True, collate_fn=collate_fn)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, \n",
    "                              num_workers=8, drop_last=True, collate_fn=collate_fn)\n",
    "#     test_loader = DataLoader(test_loader, batch_size=batch_size, shuffle=True, \n",
    "#                              num_workers=8, drop_last=True, collate_fn=collate_fn)\n",
    "    \n",
    "    print(len(train_dataset), len(valid_dataset))\n",
    "    \n",
    "    if model_type == \"gender\":\n",
    "        model = ClickRNN(input_dim=800, hidden_dim=hidden_dim, output_dim=1, \n",
    "                         n_layers=2, batch_size=batch_size, train_on_gpu=train_on_gpu)\n",
    "    elif model_type == \"age\":\n",
    "        model = ClickRNN(input_dim=800, hidden_dim=hidden_dim, output_dim=10, \n",
    "                         n_layers=2, batch_size=batch_size, train_on_gpu=train_on_gpu)\n",
    "        \n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        betas=(0.9, 0.99)\n",
    "    )\n",
    "    \n",
    "    if model_path != None:\n",
    "        map_location = lambda storage, loc: storage\n",
    "        checkpoint = torch.load(model_path, map_location=map_location)\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "        last_epoch = checkpoint[\"epoch\"]\n",
    "        lr = checkpoint[\"lr\"]\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    last_epoch = -1\n",
    "    previous_loss = 1000\n",
    "    best_test_acc = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(max_epoch):\n",
    "        if epoch < last_epoch:\n",
    "            continue\n",
    "            \n",
    "        # ========================================START TRAIN============================================\n",
    "        # train\n",
    "        model.train()\n",
    "        if model_type == \"gender\":\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        elif model_type == \"age\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        loss_meter = meter.AverageValueMeter()\n",
    "        acc_meter = meter.AverageValueMeter()\n",
    "        loss_meter.reset()\n",
    "        acc_meter.reset()\n",
    "        \n",
    "        for ii, (lengths, embed_features, age, gender) in tqdm(enumerate(train_loader)):\n",
    "            # input: [batch, time_step, input_size]\n",
    "            if model_type == \"gender\":\n",
    "                label = torch.Tensor(gender) - 1\n",
    "            elif model_type == \"age\":\n",
    "                label = torch.Tensor(age) - 1\n",
    "                \n",
    "            embed_features = embed_features.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            out, length, _ = model(embed_features)\n",
    "            print(out.shape, label.shape)\n",
    "            \n",
    "            loss = criterion(out, label)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            acc = accuracy_score(label.cpu().data, out.cpu().data)\n",
    "            acc_meter.add(acc)\n",
    "            loss_meter.add(loss.item())\n",
    "            \n",
    "            print(\"epoch:{epoch}, lr:{lr:.5f}, train_loss:{loss:.5f}, train_acc:{acc:.5f}\".format(epoch = epoch,\n",
    "                                                                                                lr = lr,\n",
    "                                                                                                loss = loss_meter.value()[0],\n",
    "                                                                                                acc = acc_meter.value()[0]))\n",
    "        # ========================================STOP TRAIN============================================\n",
    "        # ========================================START VALID============================================\n",
    "        model.eval()\n",
    "        if model_type == \"gender\":\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        elif model_type == \"age\":\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        val_loss_meter = meter.AverageValueMeter()\n",
    "        val_acc_meter = meter.AverageValueMeter()\n",
    "        val_loss_meter.reset()\n",
    "        val_acc_meter.reset()\n",
    "        \n",
    "        for ii, (lengths, embed_features, age, gender) in tqdm(enumerate(valid_loader)):\n",
    "            # input: [batch, time_step, input_size]\n",
    "            if model_type == \"gender\":\n",
    "                label = torch.Tensor(gender) - 1\n",
    "            elif model_type == \"age\":\n",
    "                label = torch.Tensor(age) - 1\n",
    "                \n",
    "            embed_features = embed_features.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            out, length, _ = model(embed_features)\n",
    "            print(out.shape, label.shape)\n",
    "            \n",
    "            loss = criterion(out, label)\n",
    "\n",
    "            acc = accuracy_score(label.cpu().data, out.cpu().data)\n",
    "            val_acc_meter.add(acc)\n",
    "            val_loss_meter.add(loss.item())\n",
    "            \n",
    "            print(\"epoch:{epoch}, lr:{lr:.5f}, val_loss:{loss:.5f}, val_acc:{acc:.5f}\".format(epoch = epoch,\n",
    "                                                                                                lr = lr,\n",
    "                                                                                                loss = val_loss_meter.value()[0],\n",
    "                                                                                                acc = val_acc_meter.value()[0]))\n",
    "        # ========================================STOP VALID============================================\n",
    "        \n",
    "        \n",
    "        best_test_acc = max(best_test_acc, val_acc_meter.value()[0])\n",
    "        \n",
    "        if best_test_acc > val_acc_meter.value()[0]:\n",
    "            best_test_acc = val_acc_meter.value()[0]\n",
    "            best_model = model\n",
    "        print(\"best_test_auc(val) is: \", best_test_acc)\n",
    "        \n",
    "        current_loss = loss_meter.value()[0]    \n",
    "        print(\"current_loss: \", current_loss)\n",
    "        if (current_loss > previous_loss) or ((epoch + 1) % 3) == 0:\n",
    "            lr = lr * lr_decay\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        \n",
    "        previous_loss = current_loss\n",
    "        \n",
    "        # TODO 每save_every个epoch结束后保存模型参数+optimizer参数\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            prefix = \"checkpoints/LSTM_epoch{}_\".format(epoch+1)\n",
    "            file_name = time.strftime(prefix + '%m%d_%H_%M_%S.pth')\n",
    "            checkpoint = {\n",
    "                \"epoch\": epoch,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"model\": model.state_dict(),\n",
    "                \"lr\": lr\n",
    "            }\n",
    "            torch.save(checkpoint, file_name)\n",
    "            \n",
    "    # TODO 结束的时候保存final模型参数\n",
    "    file_name = time.strftime('checkpoints/LSTM_final_%m%d_%H_%M_%S.pth')\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"model\": model.state_dict(),\n",
    "        \"lr\": lr\n",
    "    }\n",
    "    torch.save(checkpoint, file_name)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = train_grouped.agg(list).reset_index()\n",
    "# train_list = pd.merge(train_list, train_user, on=\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, valid_list = train_test_split(list_grouped, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-07 21:26:24,151 : INFO : loading projection weights from checkpoints/creative_model.w2v\n",
      "2020-06-07 21:26:43,085 : INFO : loaded (3412772, 200) matrix from checkpoints/creative_model.w2v\n",
      "2020-06-07 21:26:43,088 : INFO : loading projection weights from checkpoints/ad_model.w2v\n",
      "2020-06-07 21:27:01,130 : INFO : loaded (3027360, 200) matrix from checkpoints/ad_model.w2v\n",
      "2020-06-07 21:27:01,131 : INFO : loading projection weights from checkpoints/product_model.w2v\n",
      "2020-06-07 21:27:01,320 : INFO : loaded (39056, 200) matrix from checkpoints/product_model.w2v\n",
      "2020-06-07 21:27:01,321 : INFO : loading projection weights from checkpoints/advertiser_model.w2v\n",
      "2020-06-07 21:27:01,587 : INFO : loaded (57870, 100) matrix from checkpoints/advertiser_model.w2v\n",
      "2020-06-07 21:27:01,588 : INFO : loading projection weights from checkpoints/industry_model.w2v\n",
      "2020-06-07 21:27:01,591 : INFO : loaded (331, 100) matrix from checkpoints/industry_model.w2v\n",
      "2020-06-07 21:27:01,593 : INFO : loading projection weights from checkpoints/creative_model.w2v\n",
      "2020-06-07 21:27:20,356 : INFO : loaded (3412772, 200) matrix from checkpoints/creative_model.w2v\n",
      "2020-06-07 21:27:20,358 : INFO : loading projection weights from checkpoints/ad_model.w2v\n",
      "2020-06-07 21:27:37,958 : INFO : loaded (3027360, 200) matrix from checkpoints/ad_model.w2v\n",
      "2020-06-07 21:27:37,961 : INFO : loading projection weights from checkpoints/product_model.w2v\n",
      "2020-06-07 21:27:38,148 : INFO : loaded (39056, 200) matrix from checkpoints/product_model.w2v\n",
      "2020-06-07 21:27:38,150 : INFO : loading projection weights from checkpoints/advertiser_model.w2v\n",
      "2020-06-07 21:27:38,415 : INFO : loaded (57870, 100) matrix from checkpoints/advertiser_model.w2v\n",
      "2020-06-07 21:27:38,417 : INFO : loading projection weights from checkpoints/industry_model.w2v\n",
      "2020-06-07 21:27:38,420 : INFO : loaded (331, 100) matrix from checkpoints/industry_model.w2v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2597 1280\n"
     ]
    }
   ],
   "source": [
    "model_type = \"age\"\n",
    "batch_size = 64\n",
    "hidden_dim = 200\n",
    "train_on_gpu=True\n",
    "device = torch.device(\"cuda\") if train_on_gpu else torch.device(\"cpu\")\n",
    "\n",
    "model_path = None\n",
    "lr = 1e-5\n",
    "lr_decay = 0.95\n",
    "weight_decay = 1e-5\n",
    "\n",
    "max_epoch = 50\n",
    "\n",
    "train_dataset = RecordDataset(train_list)\n",
    "valid_dataset = RecordDataset(valid_list)\n",
    "#     test_dataset = RecordDataset(test_list)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                          num_workers=8, drop_last=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, \n",
    "                          num_workers=8, drop_last=True, collate_fn=collate_fn)\n",
    "#     test_loader = DataLoader(test_loader, batch_size=batch_size, shuffle=True, \n",
    "#                              num_workers=8, drop_last=True, collate_fn=collate_fn)\n",
    "\n",
    "print(len(train_dataset), len(valid_dataset))\n",
    "\n",
    "if model_type == \"gender\":\n",
    "    model = ClickRNN(input_dim=800, hidden_dim=hidden_dim, output_dim=1, \n",
    "                     n_layers=2, batch_size=batch_size, train_on_gpu=train_on_gpu)\n",
    "elif model_type == \"age\":\n",
    "    model = ClickRNN(input_dim=800, hidden_dim=hidden_dim, output_dim=10, \n",
    "                     n_layers=2, batch_size=batch_size, train_on_gpu=train_on_gpu)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    betas=(0.9, 0.99)\n",
    ")\n",
    "\n",
    "if model_path != None:\n",
    "    map_location = lambda storage, loc: storage\n",
    "    checkpoint = torch.load(model_path, map_location=map_location)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    last_epoch = checkpoint[\"epoch\"]\n",
    "    lr = checkpoint[\"lr\"]\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "last_epoch = -1\n",
    "previous_loss = 1000\n",
    "best_test_acc = 0\n",
    "best_model = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pred(pred, model_kind):\n",
    "#     pred = pred.numpy()\n",
    "    if model_kind == \"gender\":\n",
    "        record_pred_label = pred.copy()\n",
    "        record_pred_label[pred >= 0.5] = 1\n",
    "        record_pred_label[pred < 0.5] = 0\n",
    "        record_pred_label = record_pred_label.astype(int)\n",
    "    elif model_kind == \"age\":\n",
    "        record_pred_label = [list(x).index(max(x)) for x in pred]\n",
    "\n",
    "    return record_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:01, 38.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, lr:0.00001, train_loss:2.24323, train_acc:0.20781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 47.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, lr:0.00001, val_loss:2.23713, val_acc:0.20703\n",
      "best_test_auc(val) is:  0.20703124999999997\n",
      "current_loss:  2.2432250380516052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:00, 41.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, lr:0.00001, train_loss:2.23127, train_acc:0.20469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 43.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, lr:0.00001, val_loss:2.22315, val_acc:0.20781\n",
      "best_test_auc(val) is:  0.20781249999999998\n",
      "current_loss:  2.231273198127747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:01, 37.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2, lr:0.00001, train_loss:2.21840, train_acc:0.19883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 39.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2, lr:0.00001, val_loss:2.20950, val_acc:0.20547\n",
      "best_test_auc(val) is:  0.20546875\n",
      "current_loss:  2.2184001147747043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:01, 39.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3, lr:0.00001, train_loss:2.20595, train_acc:0.19766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 44.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3, lr:0.00001, val_loss:2.19485, val_acc:0.20625\n",
      "best_test_auc(val) is:  0.20625\n",
      "current_loss:  2.2059459447860714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:01, 39.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4, lr:0.00001, train_loss:2.19292, train_acc:0.20313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 41.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4, lr:0.00001, val_loss:2.18132, val_acc:0.20547\n",
      "best_test_auc(val) is:  0.20546874999999998\n",
      "current_loss:  2.1929175198078155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:01, 39.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5, lr:0.00001, train_loss:2.17876, train_acc:0.20039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 37.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5, lr:0.00001, val_loss:2.16789, val_acc:0.20469\n",
      "best_test_auc(val) is:  0.20468750000000005\n",
      "current_loss:  2.1787645936012265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:00, 40.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6, lr:0.00001, train_loss:2.16796, train_acc:0.20391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 44.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6, lr:0.00001, val_loss:2.15692, val_acc:0.20547\n",
      "best_test_auc(val) is:  0.20546875\n",
      "current_loss:  2.1679552018642423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:01, 33.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7, lr:0.00001, train_loss:2.15888, train_acc:0.19063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 40.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7, lr:0.00001, val_loss:2.14754, val_acc:0.20547\n",
      "best_test_auc(val) is:  0.20546875\n",
      "current_loss:  2.1588837325572965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:00, 41.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8, lr:0.00001, train_loss:2.14903, train_acc:0.19648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 44.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8, lr:0.00001, val_loss:2.13889, val_acc:0.20469\n",
      "best_test_auc(val) is:  0.20468750000000002\n",
      "current_loss:  2.1490308463573453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:01, 36.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9, lr:0.00001, train_loss:2.14196, train_acc:0.20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 40.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9, lr:0.00001, val_loss:2.13225, val_acc:0.20469\n",
      "best_test_auc(val) is:  0.20468750000000002\n",
      "current_loss:  2.1419607102870946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:01, 33.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, lr:0.00001, train_loss:2.13787, train_acc:0.19062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 38.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, lr:0.00001, val_loss:2.12687, val_acc:0.20469\n",
      "best_test_auc(val) is:  0.2046875\n",
      "current_loss:  2.137865048646926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:00, 40.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11, lr:0.00001, train_loss:2.12984, train_acc:0.18594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 44.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11, lr:0.00001, val_loss:2.12362, val_acc:0.20547\n",
      "best_test_auc(val) is:  0.20546874999999998\n",
      "current_loss:  2.1298398792743685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:01, 38.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12, lr:0.00001, train_loss:2.12299, train_acc:0.19805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 44.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12, lr:0.00001, val_loss:2.11874, val_acc:0.20391\n",
      "best_test_auc(val) is:  0.20390625\n",
      "current_loss:  2.1229872226715085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:01, 39.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13, lr:0.00001, train_loss:2.12191, train_acc:0.20781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 47.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13, lr:0.00001, val_loss:2.11402, val_acc:0.20469\n",
      "best_test_auc(val) is:  0.20468749999999997\n",
      "current_loss:  2.1219120681285863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:01, 36.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14, lr:0.00001, train_loss:2.11576, train_acc:0.20234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 39.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14, lr:0.00001, val_loss:2.11088, val_acc:0.20547\n",
      "best_test_auc(val) is:  0.20546875\n",
      "current_loss:  2.1157576143741608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickRNN(\n",
       "  (lstm): LSTM(800, 200, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=400, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7ff4958d0c20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sayhi/anaconda3/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-dc7511df5534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0macc_meter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# input: [batch, time_step, input_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    if epoch < last_epoch:\n",
    "        continue\n",
    "\n",
    "    # ========================================START TRAIN============================================\n",
    "    # train\n",
    "    model.train()\n",
    "    if model_type == \"gender\":\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    elif model_type == \"age\":\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    loss_meter = meter.AverageValueMeter()\n",
    "    acc_meter = meter.AverageValueMeter()\n",
    "    loss_meter.reset()\n",
    "    acc_meter.reset()\n",
    "\n",
    "    for ii, (lengths, embed_features, age, gender) in tqdm(enumerate(train_loader)):\n",
    "        # input: [batch, time_step, input_size]\n",
    "        if model_type == \"gender\":\n",
    "            label = torch.Tensor(gender) - 1\n",
    "        elif model_type == \"age\":\n",
    "            label = torch.Tensor(age) - 1\n",
    "\n",
    "        embed_features = embed_features.to(device)\n",
    "        label = label.long()\n",
    "        label = label.to(device)\n",
    "\n",
    "        out, _ = model(embed_features)\n",
    "\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        acc = accuracy_score(label.cpu().data, transform_pred(out.cpu().data, model_type))\n",
    "        acc_meter.add(acc)\n",
    "        loss_meter.add(loss.item())\n",
    "\n",
    "    print(\"epoch:{epoch}, lr:{lr:.5f}, train_loss:{loss:.5f}, train_acc:{acc:.5f}\".format(epoch = epoch,\n",
    "                                                                                        lr = lr,\n",
    "                                                                                        loss = loss_meter.value()[0],\n",
    "                                                                                        acc = acc_meter.value()[0]))\n",
    "    # ========================================STOP TRAIN============================================\n",
    "    # ========================================START VALID============================================\n",
    "    model.eval()\n",
    "    if model_type == \"gender\":\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    elif model_type == \"age\":\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    val_loss_meter = meter.AverageValueMeter()\n",
    "    val_acc_meter = meter.AverageValueMeter()\n",
    "    val_loss_meter.reset()\n",
    "    val_acc_meter.reset()\n",
    "\n",
    "    for ii, (lengths, embed_features, age, gender) in tqdm(enumerate(valid_loader)):\n",
    "        # input: [batch, time_step, input_size]\n",
    "        if model_type == \"gender\":\n",
    "            label = torch.Tensor(gender) - 1\n",
    "        elif model_type == \"age\":\n",
    "            label = torch.Tensor(age) - 1\n",
    "\n",
    "        embed_features = embed_features.to(device)\n",
    "        label = label.long()\n",
    "        label = label.to(device)\n",
    "\n",
    "        out, _ = model(embed_features)\n",
    "        \n",
    "        loss = criterion(out, label)\n",
    "        \n",
    "        acc = accuracy_score(label.cpu().data, transform_pred(out.cpu().data, model_type))\n",
    "        val_acc_meter.add(acc)\n",
    "        val_loss_meter.add(loss.item())\n",
    "\n",
    "    print(\"epoch:{epoch}, lr:{lr:.5f}, val_loss:{loss:.5f}, val_acc:{acc:.5f}\".format(epoch = epoch,\n",
    "                                                                                        lr = lr,\n",
    "                                                                                        loss = val_loss_meter.value()[0],\n",
    "                                                                                        acc = val_acc_meter.value()[0]))\n",
    "    # ========================================STOP VALID============================================\n",
    "\n",
    "\n",
    "    best_test_acc = max(best_test_acc, val_acc_meter.value()[0])\n",
    "\n",
    "    if best_test_acc > val_acc_meter.value()[0]:\n",
    "        best_test_acc = val_acc_meter.value()[0]\n",
    "        best_model = model\n",
    "    print(\"best_test_auc(val) is: \", best_test_acc)\n",
    "\n",
    "    current_loss = loss_meter.value()[0]    \n",
    "    print(\"current_loss: \", current_loss)\n",
    "    if (current_loss > previous_loss) or ((epoch + 1) % 5) == 0:\n",
    "        lr = lr * lr_decay\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    previous_loss = current_loss\n",
    "\n",
    "    # TODO 每save_every个epoch结束后保存模型参数+optimizer参数\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        prefix = \"checkpoints/LSTM_epoch{}_\".format(epoch+1)\n",
    "        file_name = time.strftime(prefix + '%m%d_%H_%M_%S.pth')\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch,\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"model\": model.state_dict(),\n",
    "            \"lr\": lr\n",
    "        }\n",
    "        torch.save(checkpoint, file_name)\n",
    "\n",
    "# TODO 结束的时候保存final模型参数\n",
    "file_name = time.strftime('checkpoints/LSTM_final_%m%d_%H_%M_%S.pth')\n",
    "checkpoint = {\n",
    "    \"epoch\": epoch,\n",
    "    \"optimizer\": optimizer.state_dict(),\n",
    "    \"model\": model.state_dict(),\n",
    "    \"lr\": lr\n",
    "}\n",
    "torch.save(checkpoint, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = model(embed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3003, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = nn.CrossEntropyLoss()\n",
    "c(out, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_from_grouped(user_id, records, column_name, keep_uid=False):\n",
    "    if column_name == \"ad_id\":\n",
    "        model = ad_model\n",
    "    elif column_name == \"creative_id\":\n",
    "        model = creative_model\n",
    "    elif column_name == \"industry\":\n",
    "        model = industry_model\n",
    "    elif column_name == \"product_id\":\n",
    "        model = product_model\n",
    "    elif column_name == \"advertiser_id\":\n",
    "        model = advertiser_model\n",
    "    \n",
    "    if column_name == \"industry\":\n",
    "        embedding = records[column_name].apply(lambda x: np.zeros(100, ) if pd.isnull(x) else model[str(int(x))]).apply(pd.Series)\n",
    "    elif column_name == \"product_id\":\n",
    "        embedding = records[column_name].apply(lambda x: np.zeros(200, ) if pd.isnull(x) else model[str(int(x))]).apply(pd.Series)\n",
    "    else:\n",
    "        embedding = records[column_name].apply(lambda x: model[str(x)]).apply(pd.Series)\n",
    "    print(embedding.shape)\n",
    "#     embedding = embedding.mean()\n",
    "    \n",
    "    if keep_uid:\n",
    "        embedding.insert(0, \"user_id\", user_id)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "flag = 0\n",
    "for user_id, records in sample_grouped:\n",
    "    records = records.sort_values(by=\"time\")\n",
    "    \n",
    "    # ad_embedding\n",
    "    ad_embedding = get_embedding_from_grouped(user_id, records, column_name=\"ad_id\")\n",
    "    #creative_embedding\n",
    "    creative_embedding = get_embedding_from_grouped(user_id, records, column_name=\"creative_id\")\n",
    "    #product_embedding\n",
    "    product_embedding = get_embedding_from_grouped(user_id, records, column_name=\"product_id\")\n",
    "    #advertiser_embedding\n",
    "    advertiser_embedding = get_embedding_from_grouped(user_id, records, column_name=\"advertiser_id\")\n",
    "    #industry_embedding\n",
    "    industry_embedding = get_embedding_from_grouped(user_id, records, column_name=\"industry\")\n",
    "\n",
    "    embed_features = np.concatenate([ad_embedding, creative_embedding, product_embedding, advertiser_embedding, industry_embedding], axis=1)\n",
    "    print(embed_features.shape)\n",
    "    print(user_id)\n",
    "#     print(records)\n",
    "    records\n",
    "    \n",
    "    flag += 1\n",
    "    if flag >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_embed(grouped, data_type=\"sample\"):\n",
    "    flag = 0\n",
    "    if data_type == \"sample\":\n",
    "        f = open(\"embed/train/sample_embedding.csv\", \"w\")\n",
    "    elif data_type == \"train\":\n",
    "        f = open(\"embed/train/train_embedding_800_{}.csv\".format(id), \"w\")\n",
    "    else:\n",
    "        f = open(\"embed/test/n_test_embedding_800_{}.csv\".format(id), \"w\")\n",
    "    for user_id, records in tqdm(grouped):\n",
    "        records = records.sort_values(by=\"time\")\n",
    "\n",
    "        # ad_embedding\n",
    "        ad_embedding = get_embedding_from_grouped(user_id, records, column_name=\"ad_id\")\n",
    "        #creative_embedding\n",
    "        creative_embedding = get_embedding_from_grouped(user_id, records, column_name=\"creative_id\")\n",
    "        #product_embedding\n",
    "        product_embedding = get_embedding_from_grouped(user_id, records, column_name=\"product_id\")\n",
    "        #advertiser_embedding\n",
    "        advertiser_embedding = get_embedding_from_grouped(user_id, records, column_name=\"advertiser_id\")\n",
    "        #industry_embedding\n",
    "        industry_embedding = get_embedding_from_grouped(user_id, records, column_name=\"industry\")\n",
    "\n",
    "        embed_features = np.concatenate([ad_embedding, creative_embedding, product_embedding, advertiser_embedding, industry_embedding])\n",
    "        f.write(str(user_id) + ', ' + str(list(embed_features))[1:-1] + '\\n')\n",
    "        '''\n",
    "        左开右闭，下标从0开始\n",
    "        0: userid\n",
    "        [1:201]: ad_embedding\n",
    "        [201:401]: creative_embedding\n",
    "        [401:601]: product_embedding\n",
    "        [601:701]: advertiser_embedding\n",
    "        [701:801]: industry_embedding\n",
    "        '''\n",
    "        \n",
    "#         flag += 1\n",
    "#         if flag % 45000 == 0:\n",
    "#             f.close()\n",
    "#             id += 1\n",
    "#             if data_type == \"train\":\n",
    "#                 f = open(\"embed/train/train_embedding{}.csv\".format(id), \"w\")\n",
    "#             else:\n",
    "#                 f = open(\"embed/test/test_embedding{}.csv\".format(id), \"w\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_embed(sample_grouped, data_type=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_zero(value):\n",
    "    matched = value.group()\n",
    "    return matched[0] + \", \" + matched[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"embed/test/\"\n",
    "\n",
    "files = (os.listdir(root_path))\n",
    "if \".ipynb_checkpoints\" in files:\n",
    "    files.remove(\".ipynb_checkpoints\")\n",
    "if \"test_embedding_all.csv\" in files:\n",
    "    files.remove(\"test_embedding_all.csv\")\n",
    "files = [root_path + i for i in files]\n",
    "\n",
    "with open(root_path + \"test_embedding_all.csv\", \"w\") as ff:\n",
    "    for ii, file in enumerate(files):\n",
    "        print(ii)\n",
    "        f = open(file, \"r\")\n",
    "        persons = f.readlines()\n",
    "        for p in tqdm(persons):\n",
    "            p1 = re.sub(r'\\d\\s\\d', place_zero, p)\n",
    "            t = ff.write(p1)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = re.search(r'\\d\\s-', p)\n",
    "print(len(a.group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_path = \"embed/train/\"\n",
    "# i_file = root_path + \"train_embedding_all.csv\"\n",
    "# o_file = root_path + \"train_embedding_all_1.csv\"\n",
    "\n",
    "root_path = \"embed/test/\"\n",
    "i_file = root_path + \"test_embedding_all.csv\"\n",
    "o_file = root_path + \"test_embedding_all_1.csv\"\n",
    "\n",
    "with open(o_file, \"w\") as ff:\n",
    "    f = open(i_file, \"r\")\n",
    "    persons = f.readlines()\n",
    "    for p in tqdm(persons):\n",
    "        if re.search(r'\\d\\s-', p) != None:\n",
    "            p1 = re.sub(r'\\d\\s-', place_zero, p)\n",
    "            t = ff.write(p1)\n",
    "        else:\n",
    "            t = ff.write(p)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"creative_id\", \"ad_id\", \"product_id\", \"advertiser_id\", \"industry\"]\n",
    "w2v_models = [creative_model, ad_model, product_model, advertiser_model, industry_model]\n",
    "\n",
    "def transform_dataframe(train_features, column_names, w2v_models):\n",
    "    for column_name, w2v_model in zip(column_names, w2v_models):\n",
    "        print(column_name, \"START\")\n",
    "        if column_name == \"industry\":\n",
    "            embedding_df = train_features[column_name].apply(lambda x: np.zeros(100, ) if pd.isnull(x) else w2v_model[str(int(x))]).apply(pd.Series)\n",
    "        elif column_name == \"product_id\":\n",
    "            embedding_df = train_features[column_name].apply(lambda x: np.zeros(200, ) if pd.isnull(x) else w2v_model[str(int(x))]).apply(pd.Series)\n",
    "        else:\n",
    "            embedding_df = train_features[column_name].apply(lambda x: w2v_model[str(x)]).apply(pd.Series)\n",
    "        train_features = pd.concat([train_features, embedding_df], axis=1).drop(column_name, axis=1)\n",
    "        print(column_name, \"FINISH\")\n",
    "    train_features.to_csv(\"main_features.csv\", index=False)\n",
    "    print(\"FINISH save csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"embed/train/train_embedding_all_1.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np = np.loadtxt(\"embed/train/train_embedding_all_1.csv\", delimiter=\", \")\n",
    "train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = \"dataset/train/\"\n",
    "train_user_path = os.path.join(train_root, \"user.csv\")\n",
    "train_user = pd.read_csv(train_user_path, index_col=\"user_id\")\n",
    "train_user.head()\n",
    "train_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_id = train_np[:, 0]\n",
    "uid = train_user_id.astype(int)\n",
    "train_age = train_user.loc[uid, \"age\"]\n",
    "train_gender = train_user.loc[uid, \"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_np[:, 1:]\n",
    "train_age = train_age.values - 1\n",
    "train_gender = train_gender.values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, valid_features,\\\n",
    "train_age, valid_age,\\\n",
    "train_gender, valid_gender = train_test_split(train_features, train_age, train_gender, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_np == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_np[:, 401:601] == 0).sum()\n",
    "# (train_np[:, 701:801] == 0).sum()\n",
    "train_np[train_np == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_traindata_gender = lgb.Dataset(train_features, train_gender)\n",
    "lgb_traindata_age = lgb.Dataset(train_features, train_age)\n",
    "\n",
    "lgb_valdata_gender = lgb.Dataset(valid_features, valid_gender, reference=lgb_traindata_gender)\n",
    "lgb_valdata_age = lgb.Dataset(valid_features, valid_age, reference=lgb_traindata_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 性别模型的预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_model = lgb_model(model_kind=\"gender\")\n",
    "gender_model.train(lgb_traindata_gender, lgb_valdata_gender)\n",
    "gender_model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_record = pd.merge(test_click, test_ad, on=\"creative_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_record.iloc[:, [0, 2, 3, 4, 5, 6, 7, 8]]\n",
    "test_features = test_features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = gender_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np = np.loadtxt(\"embed/test/test_embedding_all_1.csv\", delimiter=\", \")\n",
    "test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd tencent_algo_2020/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, accuracy_score\n",
    "from gensim.models import word2vec, keyedvectors\n",
    "import logging\n",
    "\n",
    "from model import lgb_model\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "print(\"START loading train embedding and train user info\")\n",
    "train_np = np.loadtxt(\"embed/train/train_embedding_all_1.csv\", delimiter=\", \")\n",
    "train_np[train_np == 0] = np.nan\n",
    "\n",
    "train_root = \"dataset/train/\"\n",
    "train_user_path = os.path.join(train_root, \"user.csv\")\n",
    "train_user = pd.read_csv(train_user_path, index_col=\"user_id\")\n",
    "print(\"FINISH load train_np, train_user\")\n",
    "print(\"===========================================================================\")\n",
    "\n",
    "print(\"START get train_features, train_age, train_gender, and random split train/valid data\")\n",
    "uid = train_np[:, 0].astype(int)\n",
    "train_age = train_user.loc[uid, \"age\"]\n",
    "train_gender = train_user.loc[uid, \"gender\"]\n",
    "\n",
    "train_features = train_np[:, 1:]\n",
    "train_age = train_age.values - 1\n",
    "train_gender = train_gender.values - 1\n",
    "\n",
    "train_features, valid_features,\\\n",
    "train_age, valid_age,\\\n",
    "train_gender, valid_gender = train_test_split(train_features,\\\n",
    "                                              train_age,\\\n",
    "                                              train_gender,\\\n",
    "                                              test_size=0.33,\\\n",
    "                                              random_state=42)\n",
    "print(\"FINISH random split train/valid data\")\n",
    "print(\"===========================================================================\")\n",
    "\n",
    "print(\"START construct lgb train valid data\")\n",
    "lgb_traindata_gender = lgb.Dataset(train_features, train_gender)\n",
    "lgb_traindata_age = lgb.Dataset(train_features, train_age)\n",
    "\n",
    "lgb_valdata_gender = lgb.Dataset(valid_features, valid_gender, reference=lgb_traindata_gender)\n",
    "lgb_valdata_age = lgb.Dataset(valid_features, valid_age, reference=lgb_traindata_age)\n",
    "print(\"FINISH construct lgb train valid data\")\n",
    "print(\"===========================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入已保存模型\n",
    "gender_model = lgb_model(model_kind=\"gender\")\n",
    "gender_model.load_model()\n",
    "age_model = lgb_model(model_kind=\"age\")\n",
    "age_model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"START valid acc of predict\")\n",
    "# TODO 性别模型的预测\n",
    "valid_gender_predict = gender_model.predict(valid_features)\n",
    "valid_gender_predict = gender_model.transform_pred(valid_gender_predict)\n",
    "acc_gender = accuracy_score(valid_gender_predict, valid_gender)\n",
    "\n",
    "# TODO 年龄模型的预测\n",
    "valid_age_predict = age_model.predict(valid_features)\n",
    "valid_age_predict = age_model.transform_pred(valid_age_predict)\n",
    "acc_age = accuracy_score(np.array(valid_age_predict), valid_age)\n",
    "\n",
    "print(\"In valid data, accuracy of gender is {}, accuracy of age is {}\".format(acc_gender, acc_age))\n",
    "print(\"FINISH\")\n",
    "print(\"===========================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"START test predict\")\n",
    "test_np = np.loadtxt(\"embed/test/test_embedding_all_1.csv\", delimiter=\", \")\n",
    "test_np[test_np == 0] = np.nan\n",
    "test_uid = test_np[:, 0].astype(int)\n",
    "test_features = test_np[:, 1:]\n",
    "\n",
    "# TODO 性别模型的预测\n",
    "test_gender_predict = gender_model.predict(test_features)\n",
    "test_gender_predict = gender_model.transform_pred(test_gender_predict)\n",
    "# TODO 年龄模型的预测\n",
    "test_age_predict = age_model.predict(test_features)\n",
    "test_age_predict = age_model.transform_pred(test_age_predict)\n",
    "\n",
    "result = pd.DataFrame({\"user_id\": test_uid, \"predicted_age\": test_age_predict, \"predicted_gender\": test_gender_predict})\n",
    "result.to_csv(\"results.csv\", index=False)\n",
    "\n",
    "print(\"FINISH ALL and save result to results.csv\")\n",
    "print(\"===========================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ad, train_click, train_user, test_ad, test_click = data.load_data()\n",
    "# train_record\n",
    "train_record = pd.merge(train_click, train_ad, on=\"creative_id\")\n",
    "# test_record\n",
    "test_record = pd.merge(test_click, test_ad, on=\"creative_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = test_record.groupby(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np = np.loadtxt(\"embed/test/test_embedding_all_1.csv\", delimiter=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id, record in grouped:\n",
    "    print(user_id)\n",
    "    print(record)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
